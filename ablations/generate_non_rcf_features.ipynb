{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b292150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchgeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e85b6c",
   "metadata": {},
   "source": [
    "1. Visit https://torchgeo.readthedocs.io/en/stable/api/models.html#pretrained-weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cd01f",
   "metadata": {},
   "source": [
    "2. Under Sentinel-2, choose the correct model based on number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62249a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchgeo.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device):\n",
    "    weights = ResNet50_Weights.SENTINEL2_RGB_SECO #REPLACE WITH CHOSEN WEIGHTS\n",
    "    model = resnet50(weights=weights)\n",
    "    model.fc = nn.Identity()  #remove classification layer\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    transform = weights.transforms()\n",
    "    return model, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transform = load_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce438867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "\n",
    "def load_image(path):\n",
    "    if path.endswith(\".tif\"):\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read()  #shape [C, H, W]\n",
    "            img = torch.from_numpy(img).float() \n",
    "            #img /= 1000.0 #add normalization if needed\n",
    "    elif path.endswith(\".npy\"):\n",
    "        img = np.load(path)\n",
    "        img = torch.from_numpy(img).float()\n",
    "    else:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = transform(img)\n",
    "        return img.unsqueeze(0).to(device)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "\n",
    "def get_embedding(img_tensor):\n",
    "    img_tensor = Resize((224, 224))(img_tensor)\n",
    "    img_tensor = transform(img_tensor.permute(1, 2, 0).cpu().numpy())\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(img_tensor)  #shape [1, 2048] or depending on model...\n",
    "    return embedding.squeeze(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1390bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def process_images_to_feather(image_paths, output_feather):\n",
    "    records = []\n",
    "\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            img = load_image(path)\n",
    "            #may need other processing, or to select certain bands\n",
    "            embedding = get_embedding(img)\n",
    "            record = {\"image\": os.path.basename(path)}\n",
    "            record.update({f\"f{i}\": v for i, v in enumerate(embedding)})\n",
    "            records.append(record)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {path} â€” {e}\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_feather(output_feather)\n",
    "    print(f\"Saved to {output_feather}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760c480",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list() #insert image path directories\n",
    "output_feather = \"sentinel2_embeddings.feather\"\n",
    "\n",
    "process_images_to_feather(image_paths, output_feather)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "togo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
